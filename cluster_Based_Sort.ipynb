{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit_aer import Aer\n",
    "import time\n",
    "\n",
    "# Cache for storing quantum circuits to avoid recreating them\n",
    "circuit_cache = {}\n",
    "\n",
    "def create_oracle(values, target_idx, num_qubits):\n",
    "    st = time.time()\n",
    "    cache_key = f'oracle_{target_idx}_{num_qubits}'\n",
    "    if cache_key in circuit_cache:\n",
    "        return circuit_cache[cache_key]\n",
    "\n",
    "    oracle = QuantumCircuit(num_qubits)\n",
    "    for i in range(num_qubits):\n",
    "        if (target_idx >> i) & 1:\n",
    "            oracle.x(i)\n",
    "    \n",
    "    if num_qubits == 1:\n",
    "        oracle.h(0)\n",
    "        oracle.z(0)\n",
    "        oracle.h(0)\n",
    "    elif num_qubits > 3:\n",
    "        mid = num_qubits // 2\n",
    "        oracle.h(num_qubits - 1)\n",
    "        oracle.mcx(list(range(mid)), mid)\n",
    "        oracle.mcx(list(range(mid, num_qubits - 1)), num_qubits - 1)\n",
    "        oracle.h(num_qubits - 1)\n",
    "    else:\n",
    "        oracle.h(num_qubits - 1)\n",
    "        if num_qubits == 2:\n",
    "            oracle.cx(0, 1)\n",
    "        else:\n",
    "            oracle.mcx(list(range(num_qubits - 1)), num_qubits - 1)\n",
    "    \n",
    "    for i in range(num_qubits):\n",
    "        if (target_idx >> i) & 1:\n",
    "            oracle.x(i)\n",
    "    circuit_cache[cache_key] = oracle\n",
    "    et = time.time()\n",
    "    print(f\"create_oracle time = {et-st}\")\n",
    "    return oracle\n",
    "\n",
    "def create_diffusion(num_qubits):\n",
    "    st = time.time()\n",
    "    cache_key = f'diffusion_{num_qubits}'\n",
    "    if cache_key in circuit_cache:\n",
    "        return circuit_cache[cache_key]\n",
    "\n",
    "    diffusion = QuantumCircuit(num_qubits + 1)\n",
    "    for qubit in range(num_qubits):\n",
    "        diffusion.h(qubit)\n",
    "    for qubit in range(num_qubits):\n",
    "        diffusion.x(qubit)\n",
    "    chunk_size = 3\n",
    "    for i in range(0, num_qubits - 1, chunk_size):\n",
    "        control_qubits = list(range(i, min(i + chunk_size, num_qubits - 1)))\n",
    "        if len(control_qubits) > 0:\n",
    "            diffusion.h(num_qubits)\n",
    "            diffusion.mcx(control_qubits, num_qubits)\n",
    "            diffusion.h(num_qubits)\n",
    "    for qubit in range(num_qubits):\n",
    "        diffusion.x(qubit)\n",
    "    for qubit in range(num_qubits):\n",
    "        diffusion.h(qubit)\n",
    "    circuit_cache[cache_key] = diffusion\n",
    "    et = time.time()\n",
    "    print(f\"create_diffusion = {et-st}\")\n",
    "    return diffusion\n",
    "\n",
    "def grover_find_min_index(values):\n",
    "    st = time.time()\n",
    "    n = len(values)\n",
    "    num_bits = max(1, int(np.ceil(np.log2(n))))\n",
    "    min_idx = np.argmin(values)\n",
    "    \n",
    "    qr = QuantumRegister(num_bits + 1, 'q')\n",
    "    cr = ClassicalRegister(num_bits, 'c')\n",
    "    circuit = QuantumCircuit(qr, cr)\n",
    "    \n",
    "    for i in range(num_bits):\n",
    "        circuit.h(qr[i])\n",
    "    \n",
    "    iterations = int(np.pi/4 * np.sqrt(2**num_bits))\n",
    "    oracle = create_oracle(values, min_idx, num_bits + 1)\n",
    "    diffusion = create_diffusion(num_bits)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        circuit = circuit.compose(oracle)\n",
    "        circuit = circuit.compose(diffusion)\n",
    "    \n",
    "    for i in range(num_bits):\n",
    "        circuit.measure(qr[i], cr[i])\n",
    "    \n",
    "    backend = Aer.get_backend('aer_simulator')\n",
    "    result = backend.run(circuit, shots=1000).result()\n",
    "    counts = result.get_counts()\n",
    "    max_count_result = max(counts.items(), key=lambda x: x[1])[0]\n",
    "    et = time.time()\n",
    "    print(f\" grover find min index time = {et -st}\")\n",
    "\n",
    "    return int(max_count_result, 2) % n\n",
    "\n",
    "def quantum_sort_cluster(cluster_df, sort_column):\n",
    "    st=time.time()\n",
    "    if len(cluster_df) == 0:\n",
    "        return cluster_df\n",
    "    \n",
    "    df = cluster_df.copy()\n",
    "    sorted_indices = []\n",
    "    values = df[sort_column].tolist()\n",
    "    remaining_indices = list(range(len(values)))\n",
    "    \n",
    "    while remaining_indices:\n",
    "        remaining_values = [values[i] for i in remaining_indices]\n",
    "        min_idx = grover_find_min_index(remaining_values)\n",
    "        actual_idx = remaining_indices[min_idx]\n",
    "        sorted_indices.append(actual_idx)\n",
    "        remaining_indices.remove(actual_idx)\n",
    "    \n",
    "    et=time.time()\n",
    "    print(f\"quantum_sort_cluster time = {et -st}\")\n",
    "    return df.iloc[sorted_indices].reset_index(drop=True)\n",
    "\n",
    "def cluster_based_quantum_sort(input_csv, sort_column, n_clusters=4):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Read and preprocess data\n",
    "    df = pd.read_csv(input_csv)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    if sort_column not in df.columns:\n",
    "        print(f\"Column '{sort_column}' not found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Original Data:\\n\", df)\n",
    "    \n",
    "    # Perform clustering\n",
    "    clustering_data = df[[sort_column]]\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(clustering_data)\n",
    "    \n",
    "    # Get unique clusters and sort them to ensure consistent processing order\n",
    "    unique_clusters = sorted(df['cluster'].unique())#it is storing uniq cluster ids \n",
    "    all_sorted = []\n",
    "    \n",
    "    # Process each cluster exactly once with synchronized messages\n",
    "    for cluster_id in unique_clusters:\n",
    "        cluster_df = df[df['cluster'] == cluster_id].drop(columns=['cluster'])\n",
    "        cluster_size = len(cluster_df)\n",
    "        print(f\"\\nProcessing Cluster {cluster_id} (size {cluster_size})\")\n",
    "        \n",
    "        # Process the cluster\n",
    "        sorted_cluster = quantum_sort_cluster(cluster_df, sort_column)\n",
    "        all_sorted.append(sorted_cluster)\n",
    "        \n",
    "        # Print completion message for the current cluster only\n",
    "        print(f\"Completed Cluster {cluster_id}\")\n",
    "    \n",
    "    # Combine all sorted clusters\n",
    "    merged_df = pd.concat(all_sorted, ignore_index=True)\n",
    "    # final_sorted_df = merged_df.sort_values(by=sort_column).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nFinal Sorted Data:\")\n",
    "    print(merged_df)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Total execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    circuit_cache.clear()\n",
    "    cluster_based_quantum_sort('student_dataset.csv', sort_column=\"Roll No.\", n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not int\n",
      "False\n",
      "Not int\n",
      "Not int\n",
      "True\n",
      "done\n",
      "Not int\n",
      "Not int\n",
      "{'Student_Names': 0, 'Phone_No.': 0, 'Math': 0, 'Physics': 0, 'Chemistry': 0, 'Grade': 0, 'Comment': 0, 'Roll No.': 4, 'School Name': 0, 'Student Address': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def quantumRollNoSort(df):  \n",
    "    result = {}\n",
    "    for column in df.columns:\n",
    "        col_data = df[column]\n",
    "        if (pd.api.types.is_integer_dtype(col_data)) : # main thing for being roll no\n",
    "                stringRoll = {}\n",
    "                #trying to convert the int type into string type\n",
    "                try:\n",
    "                    # they are array of type string\n",
    "                    stringRoll['strS'] =[str(i) for i in (col_data.head(10))]#first 10 nums\n",
    "                    stringRoll['strM'] = [str(i) for i in col_data.iloc[int(len(col_data)/2)-5: int(len(col_data)/2)+5]]#mid 10 nums in string\n",
    "                    stringRoll['strE'] =  [str(i) for i in col_data.iloc[len(col_data)-10:len(col_data)]]\n",
    "                    arr = np.array(list(stringRoll.values()))\n",
    "                    arr = (arr.flatten())\n",
    "                    lenOfEachEleInKeys= {}\n",
    "                    for i in stringRoll.keys():#this is iterating for keys \n",
    "                        for j in stringRoll[i]:# this is iterating for 10 values in each keys \n",
    "                            if (len(j) == len(stringRoll[i][1])) and len(j) >= 5: #checking for each roll if they are of same length\n",
    "                                lenOfEachEleInKeys[i] = len(j)\n",
    "                                # print(\"almost\")\n",
    "                            else:\n",
    "                                result [column] =0\n",
    "                                continue \n",
    "                            \n",
    "                    if len(set(lenOfEachEleInKeys.values())) == 1:\n",
    "                                isSame = all((x.startswith(arr[1][0])) for x in arr)\n",
    "                                print(isSame)\n",
    "                                if isSame:\n",
    "                                    result[column] = 4\n",
    "                                    print(\"done\")\n",
    "                                    continue\n",
    "                except:\n",
    "                    print(\"except\")\n",
    "                    result[column] = 0\n",
    "                    continue\n",
    "        else:\n",
    "            print(\"Not int\")\n",
    "            result[column] = 0\n",
    "            continue\n",
    "            \n",
    "    return result\n",
    "\n",
    "df = pd.read_csv('student_dataset.csv')\n",
    "r = quantumRollNoSort(df)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016c4f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "           f1      f2      f3      f4      f5      f6      f7    f596    f597  \\\n",
      "0    -0.4394 -0.0930  0.1718  0.4620  0.6226  0.4704  0.3578  0.6410  0.6154   \n",
      "1    -0.4348 -0.1198  0.2474  0.4036  0.5026  0.6328  0.4948  1.0000  0.7272   \n",
      "2    -0.2330  0.2124  0.5014  0.5222 -0.3422 -0.5840 -0.7168  0.2380  0.1904   \n",
      "3    -0.3808 -0.0096  0.2602  0.2554 -0.4290 -0.6746 -0.6868  0.5252  0.3670   \n",
      "4    -0.3412  0.0946  0.6082  0.6216 -0.1622 -0.3784 -0.4324  0.4688  0.5626   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "1487 -0.2232  0.1542  0.3394  0.3720  0.5100  0.5970  0.3104  0.5068  0.3698   \n",
      "1488 -0.2552  0.0776  0.1948  0.5122  0.6522  0.6258  0.4934  0.1818  0.3454   \n",
      "1489 -0.3188 -0.0318  0.1354  0.2988  0.7132  0.6374  0.5140 -0.1276  0.4042   \n",
      "1490 -0.3636 -0.1448  0.3064  0.4074  0.5320  0.6262  0.3670 -0.0176  0.2280   \n",
      "1491 -0.3236  0.0522  0.5156  0.9832  1.0000  0.4488  0.8038  0.1070  0.1572   \n",
      "\n",
      "        f598  ...    f609    f610    f611    f612    f613    f614    f615  \\\n",
      "0     1.0000  ...  0.4102  0.2052  0.3846  0.3590  0.5898  0.3334  0.6410   \n",
      "1     0.4772  ...  0.0000  0.2954  0.2046  0.4772  0.0454  0.2046  0.4318   \n",
      "2     0.5080  ... -0.1112 -0.0476 -0.1746  0.0318 -0.0476  0.1112  0.2540   \n",
      "3     0.9136  ... -0.0504 -0.0360 -0.1224  0.1366  0.2950  0.0792 -0.0072   \n",
      "4     0.5938  ...  0.1562  0.3124  0.2500 -0.0938  0.1562  0.3124  0.3124   \n",
      "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "1487  0.8630  ...  0.5616  0.3424  0.5068  0.5616 -0.4794  0.0136 -0.2602   \n",
      "1488  0.6910  ...  0.1454  0.0728  0.2546  0.3090 -0.0182 -0.2000 -0.2364   \n",
      "1489  0.5106  ...  0.4894  0.5320  0.3192  0.1702 -0.2978 -0.2340 -0.4468   \n",
      "1490  0.3334  ...  0.0000 -0.0350  0.1228  0.1052  0.0176 -0.0702 -0.0878   \n",
      "1491  0.1824  ...  0.2328  0.3334  0.1698  0.1070  0.1824 -0.0440 -0.0062   \n",
      "\n",
      "        f616    f617  class  \n",
      "0     0.5898 -0.4872    '1'  \n",
      "1     0.4546 -0.0910    '1'  \n",
      "2     0.1588 -0.4762    '2'  \n",
      "3     0.0936 -0.1510    '2'  \n",
      "4     0.2188 -0.2500    '3'  \n",
      "...      ...     ...    ...  \n",
      "1487 -0.4520 -0.6438   '13'  \n",
      "1488 -0.3454 -0.6910   '13'  \n",
      "1489 -0.5106 -0.7660   '14'  \n",
      "1490 -0.3158 -0.5614   '14'  \n",
      "1491  0.1950  0.0188   '15'  \n",
      "\n",
      "[1492 rows x 30 columns]\n",
      "\n",
      "Sorting Cluster 0 (size 97):\n",
      "\n",
      "Sorting Cluster 1 (size 88):\n",
      "\n",
      "Sorting Cluster 2 (size 84):\n",
      "\n",
      "Sorting Cluster 3 (size 105):\n",
      "\n",
      "Sorting Cluster 4 (size 87):\n",
      "\n",
      "Sorting Cluster 5 (size 125):\n",
      "\n",
      "Sorting Cluster 6 (size 18):\n",
      "\n",
      "Sorting Cluster 7 (size 69):\n",
      "\n",
      "Sorting Cluster 8 (size 87):\n",
      "\n",
      "Sorting Cluster 9 (size 31):\n",
      "\n",
      "Sorting Cluster 10 (size 111):\n",
      "\n",
      "Sorting Cluster 11 (size 38):\n",
      "\n",
      "Sorting Cluster 12 (size 84):\n",
      "\n",
      "Sorting Cluster 13 (size 64):\n",
      "\n",
      "Sorting Cluster 14 (size 105):\n",
      "\n",
      "Sorting Cluster 15 (size 2):\n",
      "\n",
      "Sorting Cluster 16 (size 87):\n",
      "\n",
      "Sorting Cluster 17 (size 58):\n",
      "\n",
      "Sorting Cluster 18 (size 93):\n",
      "\n",
      "Sorting Cluster 19 (size 59):\n",
      "\n",
      "Final Sorted Data:\n",
      "          f1      f2      f3      f4      f5      f6      f7    f596    f597  \\\n",
      "0    -0.9076 -0.6982 -0.6690 -0.0998  0.1630  0.3188  0.2944  0.2968  0.3626   \n",
      "1    -0.4332 -0.4214 -0.5712 -0.5800 -0.8590 -0.8560 -0.8356  0.9310  0.2068   \n",
      "2    -0.9580 -0.4784 -0.4878 -0.3084 -0.1594 -0.0594  0.2666  0.7752  0.9776   \n",
      "3    -0.8696 -0.5144 -0.4420 -0.1376  0.1086  0.2536  0.3116  0.8394  0.4890   \n",
      "4    -0.9896 -0.4078 -0.4244  0.0476  0.1884  0.6314  0.5446  0.9048  0.6826   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "1487  0.0082  0.6886  1.0000  0.6722  0.5246  0.4590 -0.3934  0.6330  0.3212   \n",
      "1488 -0.1438  0.3938  1.0000  0.9562 -0.1438 -0.1876 -0.7126  0.9166  0.8612   \n",
      "1489  0.0538  0.9616  1.0000  0.1770 -0.4000 -0.6230 -0.7616  1.0000  0.6904   \n",
      "1490  0.1298  0.2978  1.0000  0.9796  0.3232  0.4352 -0.2264  0.8700  0.7398   \n",
      "1491  0.0806  0.6398  1.0000  0.8136  0.4492  0.1440 -0.3220  0.7500  0.6052   \n",
      "\n",
      "        f598  ...    f609    f610    f611    f612    f613    f614    f615  \\\n",
      "0     0.4066  ...  0.2308  0.2088  0.0550  0.2748  0.2748  0.5384  0.3186   \n",
      "1     0.5172  ...  0.0690  0.2068  0.1034  0.4828  0.5172  0.4828  0.6552   \n",
      "2     1.0000  ...  0.3258  0.3708  0.2584  0.2134  0.4158  0.3932  0.0786   \n",
      "3     0.5036  ... -0.0656 -0.1824 -0.2992 -0.1386 -0.1678  0.0802  0.1678   \n",
      "4     0.7142  ...  0.7460  0.8412  0.9682  0.9048  0.2698  0.5556  0.4604   \n",
      "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "1487  0.5964  ...  0.8532  0.7432  0.6698  1.0000  0.7248  0.6698  0.2478   \n",
      "1488  0.7778  ...  0.4444  0.3056  0.3056  0.4166  0.5278  0.3334  0.3334   \n",
      "1489  0.5000  ...  0.3810  0.3334  0.3334  0.3572  0.5714  0.7380  0.2380   \n",
      "1490  0.2032  ... -0.2682 -0.1382 -0.3658 -0.1382 -0.0570 -0.4308 -0.3822   \n",
      "1491  0.5394  ... -0.2236  0.1578  0.3422  0.4342  0.3158  0.1184 -0.2764   \n",
      "\n",
      "        f616    f617  class  \n",
      "0     0.0990 -0.0990    '7'  \n",
      "1     0.1724 -0.1724   '26'  \n",
      "2     0.0338 -0.2808    '9'  \n",
      "3    -0.1970 -0.2116   '24'  \n",
      "4     0.1112 -0.4286   '15'  \n",
      "...      ...     ...    ...  \n",
      "1487  0.1560 -0.1192   '25'  \n",
      "1488 -0.0834 -0.5000   '22'  \n",
      "1489 -0.0714 -0.2380   '21'  \n",
      "1490 -0.4796 -0.5772   '25'  \n",
      "1491 -0.6448 -0.7764   '25'  \n",
      "\n",
      "[1492 rows x 30 columns]\n",
      "Total time for classical implementation = 0.06018686294555664 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "def classical_sort_cluster(cluster_df, sort_column):\n",
    "    return cluster_df.sort_values(by=sort_column).reset_index(drop=True)\n",
    "\n",
    "def classical_cluster_based_sort(input_csv, sort_column, n_clusters=4):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df = pd.read_csv(input_csv)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    if sort_column not in df.columns:\n",
    "        print(f\"Column '{sort_column}' not found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Original Data:\\n\", df)\n",
    "    \n",
    "    clustering_data = df[[sort_column]]\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(clustering_data)\n",
    "    \n",
    "    all_sorted = []\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_df = df[df['cluster'] == cluster_id].drop(columns=['cluster'])\n",
    "        print(f\"\\nSorting Cluster {cluster_id} (size {len(cluster_df)}):\")\n",
    "        sorted_cluster = classical_sort_cluster(cluster_df, sort_column)\n",
    "        all_sorted.append(sorted_cluster)\n",
    "    \n",
    "    merged_df = pd.concat(all_sorted, ignore_index=True)\n",
    "    final_sorted_df = merged_df.sort_values(by=sort_column).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nFinal Sorted Data:\")\n",
    "    print(final_sorted_df)\n",
    "    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total time for classical implementation = {total_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classical_cluster_based_sort('phpB0xrNj.csv',sort_column=\"f3\", n_clusters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7c68924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def isDfTotallyIntFloat(df):\n",
    "    return all(pd.api.types.is_numeric_dtype(dtype)  for dtype in df.dtypes)\n",
    "    \n",
    "df = pd.read_csv('student_dataset.csv')\n",
    "type = isDfTotallyIntFloat(df)\n",
    "print(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2774cc75",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseSampler' from 'qiskit.primitives' (c:\\Users\\tikes\\OneDrive\\Documents\\OneDrive\\Desktop\\ClonedProject\\Tikesh01.github.io\\.venv\\Lib\\site-packages\\qiskit\\primitives\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_aer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Aer\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_algorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Grover, AmplificationProblem\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibrary\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PhaseOracle\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantumInstance\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\OneDrive\\Documents\\OneDrive\\Desktop\\ClonedProject\\Tikesh01.github.io\\.venv\\Lib\\site-packages\\qiskit_algorithms\\__init__.py:253\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithm_job\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlgorithmJob\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithm_result\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlgorithmResult\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariational_algorithm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariationalAlgorithm, VariationalResult\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mamplitude_amplifiers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Grover, GroverResult, AmplificationProblem, AmplitudeAmplifier\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mamplitude_estimators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    256\u001b[39m     AmplitudeEstimator,\n\u001b[32m    257\u001b[39m     AmplitudeEstimatorResult,\n\u001b[32m   (...)\u001b[39m\u001b[32m    266\u001b[39m     EstimationProblem,\n\u001b[32m    267\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\OneDrive\\Documents\\OneDrive\\Desktop\\ClonedProject\\Tikesh01.github.io\\.venv\\Lib\\site-packages\\qiskit_algorithms\\variational_algorithm.py:36\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantumCircuit\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01malgorithm_result\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AlgorithmResult\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptimizerResult\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mVariationalAlgorithm\u001b[39;00m(ABC):\n\u001b[32m     40\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The Variational Algorithm Base Class.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\OneDrive\\Documents\\OneDrive\\Desktop\\ClonedProject\\Tikesh01.github.io\\.venv\\Lib\\site-packages\\qiskit_algorithms\\optimizers\\__init__.py:139\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mp_bfgs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m P_BFGS\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpowell\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m POWELL\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqnspsa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QNSPSA\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscipy_optimizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SciPyOptimizer\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mslsqp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SLSQP\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\OneDrive\\Documents\\OneDrive\\Desktop\\ClonedProject\\Tikesh01.github.io\\.venv\\Lib\\site-packages\\qiskit_algorithms\\optimizers\\qnspsa.py:23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantumCircuit\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprimitives\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit_algorithms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstate_fidelities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComputeUncompute\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspsa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SPSA, CALLBACK, TERMINATIONCHECKER, _batch_evaluate\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'BaseSampler' from 'qiskit.primitives' (c:\\Users\\tikes\\OneDrive\\Documents\\OneDrive\\Desktop\\ClonedProject\\Tikesh01.github.io\\.venv\\Lib\\site-packages\\qiskit\\primitives\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_algorithms import Grover, AmplificationProblem\n",
    "from qiskit.circuit.library import PhaseOracle\n",
    "from qiskit.utils import QuantumInstance\n",
    "\n",
    "# ----- Quantum Minimum Finding -----\n",
    "\n",
    "def index_to_bin(index, num_bits):\n",
    "    return format(index, f'0{num_bits}b')\n",
    "\n",
    "def create_oracle_expression(min_index, num_bits):\n",
    "    bin_index = index_to_bin(min_index, num_bits)\n",
    "    expr = ' & '.join([f\"{'' if bit == '1' else '~'}x{i}\" for i, bit in enumerate(bin_index)])\n",
    "    return expr\n",
    "\n",
    "def grover_find_min_index(values):\n",
    "    n = len(values)\n",
    "    num_bits = int(np.ceil(np.log2(n)))\n",
    "    padded_length = 2 ** num_bits\n",
    "\n",
    "    padded_values = values + [float('inf')] * (padded_length - n)\n",
    "    min_index = np.argmin(padded_values)\n",
    "\n",
    "    oracle_expr = create_oracle_expression(min_index, num_bits)\n",
    "    oracle = PhaseOracle(oracle_expr)\n",
    "    problem = AmplificationProblem(oracle)\n",
    "\n",
    "    backend = Aer.get_backend(\"aer_simulator\")\n",
    "    grover = Grover()\n",
    "    result = grover.amplify(problem, quantum_instance=QuantumInstance(backend))\n",
    "\n",
    "    measured_index = max(result.circuit_results.items(), key=lambda x: x[1])[0]\n",
    "    return int(measured_index, 2)\n",
    "\n",
    "def quantum_sort_cluster(cluster_df, sort_column):\n",
    "    df = cluster_df.copy().reset_index(drop=True)\n",
    "    sorted_rows = []\n",
    "\n",
    "    while not df.empty:\n",
    "        values = df[sort_column].tolist()\n",
    "        min_idx = grover_find_min_index(values)\n",
    "        sorted_rows.append(df.loc[min_idx])\n",
    "        df = df.drop(min_idx).reset_index(drop=True)\n",
    "\n",
    "    return pd.DataFrame(sorted_rows)\n",
    "\n",
    "# ----- Main Cluster-Based Hybrid Sort -----\n",
    "\n",
    "def cluster_based_quantum_sort(input_csv, sort_column, n_clusters=2, output_csv='cluster_sorted.csv'):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    if sort_column not in df.columns:\n",
    "        print(f\"Column '{sort_column}' not found.\")\n",
    "        return\n",
    "\n",
    "    print(\"Original Data:\\n\", df)\n",
    "\n",
    "    # Clustering\n",
    "    clustering_data = df[[sort_column]]\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(clustering_data)\n",
    "\n",
    "    all_sorted = []\n",
    "\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_df = df[df['cluster'] == cluster_id].drop(columns=['cluster'])\n",
    "        print(f\"\\nSorting Cluster {cluster_id} (size {len(cluster_df)}):\")\n",
    "        sorted_cluster = quantum_sort_cluster(cluster_df, sort_column)\n",
    "        all_sorted.append(sorted_cluster)\n",
    "\n",
    "    # Combine clusters and final classical sort\n",
    "    merged_df = pd.concat(all_sorted, ignore_index=True)\n",
    "    final_sorted_df = merged_df.sort_values(by=sort_column).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nFinal Sorted Data:\")\n",
    "    print(final_sorted_df)\n",
    "\n",
    "    final_sorted_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\nSorted data saved to '{output_csv}'.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    cluster_based_quantum_sort(\"data.csv\", sort_column=\"score\", n_clusters=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
