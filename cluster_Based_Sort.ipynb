{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b00335",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detectColumns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\n\u001b[32m     10\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mFiles/student_dataset.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mtype\u001b[39m = \u001b[43mdetectColumns\u001b[49m(df,df.columns)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m)    \n",
      "\u001b[31mNameError\u001b[39m: name 'detectColumns' is not defined"
     ]
    }
   ],
   "source": [
    "#Sort Different columns: \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer.primitives import Sampler\n",
    "import re\n",
    "import openpyxl\n",
    "\n",
    "df = pd.read_csv('Files/student_dataset.csv')\n",
    "type = detectColumns(df,df.columns)\n",
    "print(type)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def digitSorting(df,col,asc):\n",
    "    df[col] = df[col].astype(str)\n",
    "    df = df.sort_values(by=col,ascending=asc, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"Files/student_dataset.csv\")\n",
    "df = digitSorting(df,'Grade',asc=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32bb582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiIndex(dataFrame, colToCheck, colType, yearOnly = False, asc=True):\n",
    "    # Step 1: Get last indices of each year\n",
    "    if yearOnly == True:\n",
    "        yearsWithLastIndex = get_last_indices_of_each_year(dataFrame[colToCheck], True)\n",
    "    else: \n",
    "        if (colType['0'] == 30 or  colType['1'] == 70) or (colType['0'] == 20 or  colType['1'] == 80):\n",
    "            yearsWithLastIndex = get_last_indices_of_each_year(pd.to_datetime(dataFrame[colToCheck]),False)\n",
    "        if (colType['0'] == 70 or  colType['1'] == 30):\n",
    "            yearsWithLastIndex = None \n",
    "        else:\n",
    "            yearsWithLastIndex = get_last_indices_of_each_year(dataFrame[colToCheck], False)\n",
    "    if asc==False:\n",
    "        yearsWithLastIndex = dict(reversed(list(yearsWithLastIndex.items())))\n",
    "        \n",
    "    print(yearsWithLastIndex)\n",
    "    nameOfGroups = list(yearsWithLastIndex.keys())\n",
    "    last_indices = list(yearsWithLastIndex.values())\n",
    "\n",
    "    # Step 2: Compute counts from last indices\n",
    "    group_sizes = []\n",
    "    prev = -1\n",
    "    for idx in last_indices:\n",
    "        group_sizes.append(idx - prev)\n",
    "        prev = idx\n",
    "    print(group_sizes)\n",
    "    # Step 3: Create array per group\n",
    "    objOfGroups = {\n",
    "        f'key{i}': np.array([f'Group of {year}'] * group_sizes[i]) for i, year in enumerate(nameOfGroups)\n",
    "    }\n",
    "    \n",
    "    # Step 4: Combine into one array\n",
    "    if (colType['0'] == 70 or  colType['1'] == 30):\n",
    "        setOfV = [str(v)[:int((len(str(v))*0.65))] for v in dataFrame[colToCheck]]\n",
    "        setOfV = sorted(set(setOfV))\n",
    "    else:\n",
    "        outside = np.concatenate(list(objOfGroups.values()))\n",
    "    \n",
    "    # Step 5: Create inside index\n",
    "    inside = np.arange(len(outside))\n",
    "    \n",
    "    multi_index = pd.MultiIndex.from_arrays([outside, inside], names=[\"Group\", \"Sr No.\"])\n",
    "    \n",
    "    dataFrame = dataFrame.reindex(range(len(multi_index)))\n",
    "    dataFrame.set_index(multi_index,inplace=True,)\n",
    "    print(\"Multicalled\")\n",
    "    return dataFrame\n",
    "\n",
    "def get_last_indices_of_each_year(date_series, YearOnly=False,rol=False):\n",
    "    \n",
    "    # data_series = data_series.apply(pd.to_numeric, errors='coerce').astype('Int64')\n",
    "    if YearOnly == True:\n",
    "        print(\"yearOnly work\")\n",
    "        df = pd.DataFrame({'year': date_series}, index=np.arange(len(date_series)))\n",
    "    \n",
    "    if YearOnly == False:\n",
    "        # Extract year\n",
    "        try:\n",
    "            years = date_series.dt.year\n",
    "            # Create a DataFrame with index\n",
    "            df = pd.DataFrame({'year': years}, index=np.arange(len(date_series)))\n",
    "            print(\"Year Extracted\")\n",
    "        except:\n",
    "            #Create a DataFrame with index\n",
    "            df = pd.DataFrame({'year': date_series}, index=np.arange(len(date_series)))\n",
    "        \n",
    "    # Get last index of each year group\n",
    "    last_indices = df.groupby('year').apply(lambda x: x.index[-1]).to_dict()\n",
    "        \n",
    "    print(\"last index called\")\n",
    "    return last_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dad1b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mtype\u001b[39m = {\n\u001b[32m     43\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m0\u001b[39m\u001b[33m'\u001b[39m : \u001b[32m70\u001b[39m, \n\u001b[32m     44\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m : \u001b[32m30\u001b[39m\n\u001b[32m     45\u001b[39m         }\n\u001b[32m     46\u001b[39m df\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m df = \u001b[43mmultiIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolToCheck\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRoll No.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcolType\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mmultiIndex\u001b[39m\u001b[34m(dataFrame, colToCheck, colType, yearOnly, asc)\u001b[39m\n\u001b[32m     13\u001b[39m     yearsWithLastIndex = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(yearsWithLastIndex.items())))\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(yearsWithLastIndex)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m nameOfGroups = \u001b[38;5;28mlist\u001b[39m(\u001b[43myearsWithLastIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m())\n\u001b[32m     17\u001b[39m last_indices = \u001b[38;5;28mlist\u001b[39m(yearsWithLastIndex.values())\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Step 2: Compute counts from last indices\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sortRollCol(df, col,asc):\n",
    "    digits_df = df[col].astype(str).apply(lambda x: pd.Series(list(x)))\n",
    "    \n",
    "    digits_df['original_index'] = df.index\n",
    "    \n",
    "    sorted_digits_df = recursiveSort(digits_df)\n",
    "\n",
    "    sorted_indices = sorted_digits_df['original_index'].values\n",
    "    if asc == False:\n",
    "        sorted_indices = reversed(sorted_indices)\n",
    "        \n",
    "    sorted_df = df.loc[sorted_indices].reset_index(drop=True)\n",
    "\n",
    "    return sorted_df\n",
    "\n",
    "\n",
    "def recursiveSort(df_digits, col=0):\n",
    "    if col >= int(len(df_digits.columns) - 1):  # exclude 'original_index' column\n",
    "        return df_digits\n",
    "\n",
    "    # Sort by the current digit column\n",
    "    df_digits = df_digits.sort_values(by=col, kind='stable', ignore_index=True)\n",
    "\n",
    "    # Group by current digit and recursively sort each group\n",
    "    result = []\n",
    "    for value, group in df_digits.groupby(col, sort=False):\n",
    "        sorted_group = recursiveSort(group.reset_index(drop=True), col + 1)\n",
    "        result.append(sorted_group)\n",
    "    \n",
    "    return pd.concat(result, ignore_index=True)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "df = pd.read_csv('Files/student_dataset.csv')  # Your dataset with 'Roll No.'\n",
    "df.sort_values(by='Roll No.',inplace=True,ignore_index=True)\n",
    "type = {\n",
    "        '0' : 70, \n",
    "        '1' : 30\n",
    "        }\n",
    "df\n",
    "df = multiIndex(df,colToCheck='Roll No.',colType=type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06935ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detectColumns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     31\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mFiles/twitter_training.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m col = \u001b[43mdetectColumns\u001b[49m(df,df.columns)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.isna().sum())\n\u001b[32m     34\u001b[39m df = dataClean(df,col)\n",
      "\u001b[31mNameError\u001b[39m: name 'detectColumns' is not defined"
     ]
    }
   ],
   "source": [
    "def dataClean(df,colTypes):\n",
    "    for i in df.index[(df.isna().sum(axis=1)==len(df.columns))]:\n",
    "        df.drop(index=i, inplace=True)\n",
    "        \n",
    "    for i in colTypes.keys():\n",
    "        if df[i].isna().sum() >=len(df[i])-2:\n",
    "            df.drop(columns=[i],inplace=True)\n",
    "            continue\n",
    "        \n",
    "        if df[i].isna().sum() != 0:#IF column has no type\n",
    "                print(i)\n",
    "                if (colTypes[i]['0'] == 60 or colTypes[i]['1'] == 40): # if column is type of year only\n",
    "                    df[i] = df[i].fillna(2100)\n",
    "                elif colTypes[i]['0'] == 30 or  colTypes[i]['1'] == 70:#if column is type of date only \n",
    "                    df[i] = df[i].fillna(pd.to_datetime('2030-01-01'))\n",
    "                elif colTypes[i]['0'] == 20 or  colTypes[i]['1'] == 80 :#if column is type of date and time \n",
    "                    df[i]= df[i].fillna('2030-01-01')\n",
    "                elif colTypes[i]['0'] == 70 or colTypes[i]['1']==30: #Roll no type\n",
    "                    df[i] = df[i].fillna(000000)\n",
    "                elif colTypes[i]['1']==50 or colTypes[i]['0']==50:#if it is of type id \n",
    "                    df[i]=df[i].fillna(\"Unknown\")\n",
    "                elif colTypes[i]['0']==90 or colTypes[i]['1'] ==10:#if it of type oneor2digit\n",
    "                    df[i] = df[i].fillna(0)\n",
    "                elif colTypes[i]['0'] == 80 or  colTypes[i]['1'] == 20 : #if it type of nemric\n",
    "                    df[i]=df[i].fillna(0.0)\n",
    "                elif colTypes[i]['0'] == 40 or  colTypes[i]['1'] == 60 : #string or object\n",
    "                    df[i] = df[i].fillna('NULL-NAN')\n",
    "        continue\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('Files/twitter_training.csv')\n",
    "col = detectColumns(df,df.columns)\n",
    "print(df.isna().sum())\n",
    "df = dataClean(df,col)\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "04fd8dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13      Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "20      that was the first borderlands session in a lo...\n",
      "26      The biggest disappointment of my life came a y...\n",
      "51      Blaming Sight for Tardiness! A little bit of b...\n",
      "64                                                   .. [\n",
      "                              ...                        \n",
      "4754    At the same time, despite the fact that there ...\n",
      "4755                                                  NaN\n",
      "4756                                                  NaN\n",
      "4757                                                  NaN\n",
      "4796                               buff.ly / 33Q7U7s.....\n",
      "Name: Comments, Length: 288, dtype: object\n",
      "4800\n",
      "4512\n"
     ]
    }
   ],
   "source": [
    "def FindDuplicateInStrOrOBj(series):\n",
    "    series = pd.Series(series)\n",
    "    series = series[series.duplicated()==True]\n",
    "    return series\n",
    "\n",
    "df = pd.read_csv('Files/twitter_training.csv')\n",
    "dup = FindDuplicateInStrOrOBj(df['Comments'])\n",
    "print(dup)\n",
    "print(len(df))\n",
    "df.drop_duplicates(inplace=True,subset=['Comments'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "34b6ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time By Model  7.434240818023682\n",
      "Time in Normalizig : 0.002997875213623047\n",
      "Time clustering : 0.714836597442627\n",
      "Silhouette Score: 0.08340984\n",
      "Time in Normalizig : 0.04400444030761719\n",
      "    Employee_ID Task_ID  Start_Date  End_Date  login Time Logout_Time\n",
      "985       E9828  T17194  25-01-2025       NaN         NaN    18:31:11\n",
      "999       E9115  T37857  30-01-2025       NaN         NaN    19:06:08\n",
      "572       E5099  T11336  10-01-2025       NaN         NaN    18:16:00\n",
      "573       E8987  T68207  26-01-2025       NaN         NaN    18:29:35\n",
      "574       E9529  T85829  23-01-2025       NaN         NaN    18:39:01\n",
      "..          ...     ...         ...       ...         ...         ...\n",
      "969       E6790  T23862  23-12-2024       NaN         NaN    17:39:57\n",
      "37        E2356  T35740  04-01-2025       NaN         NaN    19:40:28\n",
      "34        E6234  T92956  15-01-2025       NaN         NaN    20:28:31\n",
      "31        E5396  T59696  05-12-2024       NaN         NaN    18:00:33\n",
      "25        E9638  T56134  25-12-2024       NaN         NaN    18:37:36\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Files/employee_time_log.csv') \n",
    "df = kmeansOnString(df,'Employee_ID')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "952da5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "def kmeansOnString(df,col):\n",
    "    phrase = (df[col]).astype(str)\n",
    "    # Step 1: Convert strings to embeddings using a Sentence Transformer (BERT-based model)\n",
    "    st = time.time()\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # a lightweight, efficient model\n",
    "    embeddings = model.encode(phrase)\n",
    "    et = time.time()\n",
    "    print(\"time By Model \", et-st)\n",
    "    \n",
    "    st = et\n",
    "    # Optionally, normalize embeddings if needed:\n",
    "    from sklearn.preprocessing import normalize\n",
    "    embeddings = normalize(embeddings)\n",
    "    et = time.time()\n",
    "    print(f\"Time in Normalizig : {et-st}\")\n",
    "    \n",
    "    st = et\n",
    "    # Step 2: Apply KMeans clustering on these embeddings\n",
    "    # Using n_init and max_iter helps ensure stable convergence.\n",
    "    k =  int(np.ceil(len(df[col]) / 80))# number of clusters\n",
    "    kmeans = KMeans(n_clusters=7, n_init=19, max_iter=450, random_state=42)\n",
    "    df['Cluster Id'] = kmeans.fit_predict(embeddings)\n",
    "    et = time.time()\n",
    "    print(f\"Time clustering : {et-st}\")\n",
    "    \n",
    "    st = et\n",
    "    # Step 3: Evaluate the clustering with Silhouette Score\n",
    "    score = silhouette_score(embeddings, df['Cluster Id'])\n",
    "    print(\"Silhouette Score:\", score)\n",
    "    et = time.time()\n",
    "    print(f\"Time in Normalizig : {et-st}\")\n",
    "    \n",
    "    df = df.sort_values(by='Cluster Id').drop(columns=['Cluster Id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "91fbbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "import pandas as pd\n",
    "import math\n",
    "def detectColumns(df, prioColumns):\n",
    "    result = {}    \n",
    "    for col in prioColumns:\n",
    "        qc =  QuantumCircuit(1,1)\n",
    "        col_data = df[col]\n",
    "        col_str = df[col].astype(str).str.strip()\n",
    "        # 3. Check for Date values (type 2)\n",
    "        if check_date_format(col_str):\n",
    "            p = 0.70000\n",
    "                \n",
    "        # 4. Check for DateTime values (type 3)\n",
    "        elif check_datetime_format(col_str):\n",
    "            p = 0.800000\n",
    "            \n",
    "        elif OneOr2digitDetection(col_data):\n",
    "            p = 0.100000\n",
    "        # 1. Check for Roll Numbers (type 4)\n",
    "        elif pd.api.types.is_numeric_dtype(col_data):\n",
    "            p = 0.2000\n",
    "            # 2. Check for Year values (type 1)\n",
    "            if check_year_values(col_data):\n",
    "                p = 0.40000\n",
    "            elif check_roll_number(col_data):\n",
    "                p = 0.30000\n",
    "\n",
    "        elif pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col]):\n",
    "            p = 0.600000\n",
    "            if detectIdTypeCol(col_data):\n",
    "                p = 0.5\n",
    "        \n",
    "        angle = 2 * math.asin(math.sqrt(p))\n",
    "        qc.ry(angle, 0)\n",
    "        # Initialize result as 0 (unrecognized type)\n",
    "        result[col] = measurCir(qc,0)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def check_roll_number(col_data):\n",
    "    try:\n",
    "        # Convert numbers to strings for checking patterns\n",
    "        sample_start = [str(i) for i in col_data.head(10)]\n",
    "        sample_middle = [str(i) for i in col_data.iloc[int(len(col_data)/2)-5:int(len(col_data)/2)+5]]\n",
    "        sample_end = [str(i) for i in col_data.iloc[-10:]]\n",
    "        \n",
    "        # Combine samples\n",
    "        samples = sample_start + sample_middle + sample_end\n",
    "        \n",
    "        # Check if all numbers have the same length and >= 5 digits\n",
    "        if len(set(len(str(x)) for x in samples)) == 1:\n",
    "            length = len(str(samples[0]))\n",
    "            if length >= 5:\n",
    "                # Check if all numbers start with the same digit\n",
    "                first_digits = str(samples[0])[0]\n",
    "                return all(str(x).startswith(first_digit) for x in samples)\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def check_year_values(col_data):\n",
    "    if pd.api.types.is_string_dtype(col_data):\n",
    "        try:\n",
    "            col_data = pd.to_numeric(col_data)\n",
    "        except:\n",
    "            pass\n",
    "    # Handle if column is numeric and looks like a year\n",
    "    if pd.api.types.is_numeric_dtype(col_data) or  pd.api.types.is_float_dtype(col_data) or  pd.api.types.is_integer_dtype(col_data):\n",
    "        if col_data.dropna().empty == False:\n",
    "            if pd.api.types.is_float_dtype(col_data):\n",
    "            # Check if float values have only 2 decimal places\n",
    "                if col_data.dropna().apply(lambda x: round(x, 2) == x).all():\n",
    "                    if col_data.dropna().between(1800, 2050).all():\n",
    "                        return True # Only year\n",
    "            # For integer values\n",
    "            elif col_data.dropna().between(1800, 2100).all():\n",
    "                True # Only year\n",
    "                \n",
    "    return False\n",
    "\n",
    "def check_date_format(col_str):\n",
    "    # Check for common date formats (yyyy-mm-dd, dd-mm-yyyy, etc.)\n",
    "    date_pattern = r'^\\d{1,4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,4}$'\n",
    "    return col_str.str.match(date_pattern).all()\n",
    "\n",
    "def check_datetime_format(col_str):\n",
    "    # Check for datetime format (date + time)\n",
    "    datetime_pattern = r'\\d{1,4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,4}.*\\d{1,2}:\\d{2}'\n",
    "    return col_str.str.contains(datetime_pattern).all()\n",
    "\n",
    "def detectIdTypeCol(col_data):\n",
    "    if pd.api.types.is_string_dtype(col_data):\n",
    "        pattern = r'\\b[A-Z0-9]{1,4}[-_./]?[A-Z0-9]{2,6}[-_./]?[A-Z0-9]{0,5}\\b'\n",
    "        return all(re.fullmatch(pattern, item) for item in col_data)\n",
    "    \n",
    "def OneOr2digitDetection(col_data):\n",
    "    non2Digit=0\n",
    "    for v  in col_data:\n",
    "        if len(str(v)) >= 2:\n",
    "            non2Digit=o=non2Digit+1\n",
    "    \n",
    "    if len(col_data)/2.2 > non2Digit:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def detectSimpleDtypes(col_data):\n",
    "    if pd.api.types.is_integer_dtype(col_data):\n",
    "        return 'allInt'\n",
    "    if pd.api.types.is_float_dtype(col_data):\n",
    "        if col_data.isna().all()== False:\n",
    "            return 'numaric'\n",
    "    if pd.api.types.is_string_dtype(col_data) or pd.api.types.is_object_dtype(col_data):\n",
    "        return 'str'\n",
    "    return None\n",
    "\n",
    "def clusterDateTimeCol(fContent, col,no,ascending=True):\n",
    "    if no ==1:\n",
    "        # Try to detect and sort if the column is just year values\n",
    "        fContent = fContent.sort_values(by=col,ignore_index=True, ascending=ascending)\n",
    "        fContent = fContent.reset_index(drop=True)\n",
    "    elif no == 2 or 3:\n",
    "        # Now, try to detect proper date/datetime columns\n",
    "        try:\n",
    "            # Avoid processing numeric-only or zero-filled columns\n",
    "            sample_vals = fContent[col].astype(str).str.strip().replace('0', np.nan).dropna()\n",
    "            if len(sample_vals) == 0:\n",
    "                return fContent# All values are zero or empty-like\n",
    "            \n",
    "            # Try parsing\n",
    "            try:\n",
    "                parsed_col = pd.to_datetime(fContent[col], errors='raise')\n",
    "            except:\n",
    "                parsed_col = pd.to_datetime(fContent[col], dayfirst=True, errors='raise')\n",
    "               \n",
    "            if all(parsed_col.dt.time == pd.to_datetime('00:00:00').time()) and no == 2:  # Only date\n",
    "                fContent[col] = parsed_col\n",
    "                fContent = clean_and_sort_date_column(fContent, col, ascending)\n",
    "                fContent = fContent.reset_index(drop=True)\n",
    "                # Replace original column with parsed datetime values\n",
    "            elif no == 3:  # Date + time\n",
    "                fContent[col] = parsed_col\n",
    "                fContent = handle_datetime_column(fContent, col, ascending)\n",
    "                fContent = fContent.reset_index(drop=True)\n",
    "        except Exception as e:\n",
    "            return fContent # Not a datetime column\n",
    "        \n",
    "    return fContent \n",
    "\n",
    "def clean_and_sort_date_column(dff, column_name, ascending=True):\n",
    "        try:\n",
    "            \n",
    "            # Step 2: Drop NaT (invalid formats)\n",
    "            dff = dff.dropna(subset=[column_name])\n",
    "            \n",
    "            # Step 3: Sort the DataFrame by that column\n",
    "            dff = dff.sort_values(by=column_name, ascending=ascending)\n",
    "\n",
    "            # Optional: Format to clean date string (YYYY-MM-DD)\n",
    "            dff[column_name] = dff[column_name].dt.strftime('%Y-%m-%d')\n",
    "            print(f\"{column_name} date called \")\n",
    "            return dff\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error while processing date column: {e}\")\n",
    "            return dff\n",
    "\n",
    "def handle_datetime_column(df, column_name, ascending):\n",
    "    print(f\"{column_name} dateTime\")\n",
    "    # Check if most values in column are datetime with time\n",
    "    values = df[column_name].dropna().astype(str).head(20)\n",
    "    count_datetime = sum([pd.api.is_datetime(v) for v in values])\n",
    "\n",
    "    if count_datetime >= len(values) // 2:  # At least half must be datetime-like\n",
    "        # Convert full column to datetime\n",
    "        df[column_name] = pd.to_datetime(df[column_name], errors='coerce')\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=[column_name])\n",
    "        # Sort by that column\n",
    "        df = df.sort_values(by=column_name,ascending=ascending).reset_index(drop=True)\n",
    "        print(f\"[INFO] '{column_name}' successfully recognized and sorted as datetime.\")\n",
    "    else:\n",
    "        print(f\"[INFO] '{column_name}' does not contain proper datetime with time.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "26207e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurCir(qc,q_num):\n",
    "    qc.measure(q_num,q_num)\n",
    "    simulator = AerSimulator()\n",
    "    # Transpile & run\n",
    "    compiled = transpile(qc, simulator)\n",
    "    r = simulator.run(compiled, shots=100000).result()\n",
    "    counts = r.get_counts()\n",
    "    for k,v in counts.items():\n",
    "        counts[k] = int(v/1000)\n",
    "    return counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
