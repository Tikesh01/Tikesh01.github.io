{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b00335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Student_Names': {'1': 59, '0': 40}, 'Phone_No.': {'0': 79, '1': 20}, 'Math': {'0': 79, '1': 20}, 'Physics': {'0': 80, '1': 19}, 'Chemistry': {'1': 20, '0': 79}, 'Grade': {'0': 89, '1': 10}, 'Comment': {'0': 40, '1': 59}, 'Roll No.': {'0': 69, '1': 30}, 'School Name': {'1': 59, '0': 40}, 'Student Address': {'1': 60, '0': 39}}\n"
     ]
    }
   ],
   "source": [
    "#Sort Different columns: \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer.primitives import Sampler\n",
    "import re\n",
    "import openpyxl\n",
    "\n",
    "df = pd.read_csv('Files/student_dataset.csv')\n",
    "type = detectColumns(df,df.columns)\n",
    "print(type)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06935ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num          0\n",
      "company      0\n",
      "Type         0\n",
      "Comments    41\n",
      "dtype: int64\n",
      "Comments\n",
      "Num         0\n",
      "company     0\n",
      "Type        0\n",
      "Comments    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def dataClean(df,colTypes):\n",
    "    for i in df.index[(df.isna().sum(axis=1)==len(df.columns))]:\n",
    "        df.drop(index=i, inplace=True)\n",
    "        \n",
    "    for i in colTypes.keys():\n",
    "        if df[i].isna().sum() >=len(df[i])-2:\n",
    "            df.drop(columns=[i],inplace=True)\n",
    "            continue\n",
    "        \n",
    "        if df[i].isna().sum() != 0:#IF column has no type\n",
    "                print(i)\n",
    "                if (colTypes[i]['0'] == 60 or colTypes[i]['1'] == 40): # if column is type of year only\n",
    "                    df[i] = df[i].fillna(2100)\n",
    "                elif colTypes[i]['0'] == 30 or  colTypes[i]['1'] == 70:#if column is type of date only \n",
    "                    df[i] = df[i].fillna(pd.to_datetime('2030-01-01'))\n",
    "                elif colTypes[i]['0'] == 20 or  colTypes[i]['1'] == 80 :#if column is type of date and time \n",
    "                    df[i]= df[i].fillna('2030-01-01')\n",
    "                elif colTypes[i]['0'] == 70 or colTypes[i]['1']==30: #Roll no type\n",
    "                    df[i] = df[i].fillna(000000)\n",
    "                elif colTypes[i]['1']==50 or colTypes[i]['0']==50:#if it is of type id \n",
    "                    df[i]=df[i].fillna(\"Unknown\")\n",
    "                elif colTypes[i]['0']==90 or colTypes[i]['1'] ==10:#if it of type oneor2digit\n",
    "                    df[i] = df[i].fillna(0)\n",
    "                elif colTypes[i]['0'] == 80 or  colTypes[i]['1'] == 20 : #if it type of nemric\n",
    "                    df[i]=df[i].fillna(0.0)\n",
    "                elif colTypes[i]['0'] == 40 or  colTypes[i]['1'] == 60 : #string or object\n",
    "                    df[i] = df[i].fillna('NULL-NAN')\n",
    "        continue\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('Files/twitter_training.csv')\n",
    "col = detectColumns(df,df.columns)\n",
    "print(df.isna().sum())\n",
    "df = dataClean(df,col)\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04fd8dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13      Rock-Hard La Varlope, RARE & POWERFUL, HANDSOM...\n",
      "20      that was the first borderlands session in a lo...\n",
      "26      The biggest disappointment of my life came a y...\n",
      "51      Blaming Sight for Tardiness! A little bit of b...\n",
      "64                                                   .. [\n",
      "                              ...                        \n",
      "4754    At the same time, despite the fact that there ...\n",
      "4755                                                  NaN\n",
      "4756                                                  NaN\n",
      "4757                                                  NaN\n",
      "4796                               buff.ly / 33Q7U7s.....\n",
      "Name: Comments, Length: 288, dtype: object\n",
      "4800\n",
      "4512\n"
     ]
    }
   ],
   "source": [
    "def FindDuplicateInStrOrOBj(series):\n",
    "    series = pd.Series(series)\n",
    "    series = series[series.duplicated()==True]\n",
    "    return series\n",
    "\n",
    "df = pd.read_csv('Files/twitter_training.csv')\n",
    "dup = FindDuplicateInStrOrOBj(df['Comments'])\n",
    "print(dup)\n",
    "print(len(df))\n",
    "df.drop_duplicates(inplace=True,subset=['Comments'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34b6ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time By Model  14.663967370986938\n",
      "Time in Normalizig : 0.0017213821411132812\n",
      "Time clustering : 0.7560210227966309\n",
      "Silhouette Score: 0.08340984\n",
      "Time in Normalizig : 0.04461359977722168\n",
      "    Employee_ID Task_ID  Start_Date  End_Date  login Time Logout_Time\n",
      "985       E9828  T17194  25-01-2025       NaN         NaN    18:31:11\n",
      "999       E9115  T37857  30-01-2025       NaN         NaN    19:06:08\n",
      "572       E5099  T11336  10-01-2025       NaN         NaN    18:16:00\n",
      "573       E8987  T68207  26-01-2025       NaN         NaN    18:29:35\n",
      "574       E9529  T85829  23-01-2025       NaN         NaN    18:39:01\n",
      "..          ...     ...         ...       ...         ...         ...\n",
      "969       E6790  T23862  23-12-2024       NaN         NaN    17:39:57\n",
      "37        E2356  T35740  04-01-2025       NaN         NaN    19:40:28\n",
      "34        E6234  T92956  15-01-2025       NaN         NaN    20:28:31\n",
      "31        E5396  T59696  05-12-2024       NaN         NaN    18:00:33\n",
      "25        E9638  T56134  25-12-2024       NaN         NaN    18:37:36\n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Files/employee_time_log.csv') \n",
    "df = kmeansOnString(df,'Employee_ID')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952da5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tikes\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "def kmeansOnString(df,col):\n",
    "    phrase = (df[col]).astype(str)\n",
    "    # Step 1: Convert strings to embeddings using a Sentence Transformer (BERT-based model)\n",
    "    st = time.time()\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # a lightweight, efficient model\n",
    "    embeddings = model.encode(phrase)\n",
    "    et = time.time()\n",
    "    print(\"time By Model \", et-st)\n",
    "    \n",
    "    st = et\n",
    "    # Optionally, normalize embeddings if needed:\n",
    "    from sklearn.preprocessing import normalize\n",
    "    embeddings = normalize(embeddings)\n",
    "    et = time.time()\n",
    "    print(f\"Time in Normalizig : {et-st}\")\n",
    "    \n",
    "    st = et\n",
    "    # Step 2: Apply KMeans clustering on these embeddings\n",
    "    # Using n_init and max_iter helps ensure stable convergence.\n",
    "    k =  int(np.ceil(len(df[col]) / 80))# number of clusters\n",
    "    kmeans = KMeans(n_clusters=7, n_init=19, max_iter=450, random_state=42)\n",
    "    df['Cluster Id'] = kmeans.fit_predict(embeddings)\n",
    "    et = time.time()\n",
    "    print(f\"Time clustering : {et-st}\")\n",
    "    \n",
    "    st = et\n",
    "    # Step 3: Evaluate the clustering with Silhouette Score\n",
    "    score = silhouette_score(embeddings, df['Cluster Id'])\n",
    "    print(\"Silhouette Score:\", score)\n",
    "    et = time.time()\n",
    "    print(f\"Time in Normalizig : {et-st}\")\n",
    "    \n",
    "    df = df.sort_values(by='Cluster Id').drop(columns=['Cluster Id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fbbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "import pandas as pd\n",
    "import math\n",
    "def detectColumns(df, prioColumns):\n",
    "    result = {}    \n",
    "    for col in prioColumns:\n",
    "        qc =  QuantumCircuit(1,1)\n",
    "        col_data = df[col]\n",
    "        col_str = df[col].astype(str).str.strip()\n",
    "        # 3. Check for Date values (type 2)\n",
    "        if check_date_format(col_str):\n",
    "            p = 0.70000\n",
    "                \n",
    "        # 4. Check for DateTime values (type 3)\n",
    "        elif check_datetime_format(col_str):\n",
    "            p = 0.800000\n",
    "            \n",
    "        elif OneOr2digitDetection(col_data):\n",
    "            p = 0.100000\n",
    "        # 1. Check for Roll Numbers (type 4)\n",
    "        elif pd.api.types.is_numeric_dtype(col_data):\n",
    "            p = 0.2000\n",
    "            # 2. Check for Year values (type 1)\n",
    "            if check_year_values(col_data):\n",
    "                p = 0.40000\n",
    "            elif check_roll_number(col_data):\n",
    "                p = 0.30000\n",
    "\n",
    "        elif pd.api.types.is_string_dtype(df[col]) or pd.api.types.is_object_dtype(df[col]):\n",
    "            p = 0.600000\n",
    "            if detectIdTypeCol(col_data):\n",
    "                p = 0.5\n",
    "        \n",
    "        angle = 2 * math.asin(math.sqrt(p))\n",
    "        qc.ry(angle, 0)\n",
    "        # Initialize result as 0 (unrecognized type)\n",
    "        result[col] = measurCir(qc,0)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def check_roll_number(col_data):\n",
    "    try:\n",
    "        # Convert numbers to strings for checking patterns\n",
    "        sample_start = [str(i) for i in col_data.head(10)]\n",
    "        sample_middle = [str(i) for i in col_data.iloc[int(len(col_data)/2)-5:int(len(col_data)/2)+5]]\n",
    "        sample_end = [str(i) for i in col_data.iloc[-10:]]\n",
    "        \n",
    "        # Combine samples\n",
    "        samples = sample_start + sample_middle + sample_end\n",
    "        \n",
    "        # Check if all numbers have the same length and >= 5 digits\n",
    "        if len(set(len(str(x)) for x in samples)) == 1:\n",
    "            length = len(str(samples[0]))\n",
    "            if length >= 5:\n",
    "                # Check if all numbers start with the same digit\n",
    "                first_digit = str(samples[0])[0]\n",
    "                return all(str(x).startswith(first_digit) for x in samples)\n",
    "    except:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def check_year_values(col_data):\n",
    "    if pd.api.types.is_string_dtype(col_data):\n",
    "        try:\n",
    "            col_data = pd.to_numeric(col_data)\n",
    "        except:\n",
    "            pass\n",
    "    # Handle if column is numeric and looks like a year\n",
    "    if pd.api.types.is_numeric_dtype(col_data) or  pd.api.types.is_float_dtype(col_data) or  pd.api.types.is_integer_dtype(col_data):\n",
    "        if col_data.dropna().empty == False:\n",
    "            if pd.api.types.is_float_dtype(col_data):\n",
    "            # Check if float values have only 2 decimal places\n",
    "                if col_data.dropna().apply(lambda x: round(x, 2) == x).all():\n",
    "                    if col_data.dropna().between(1800, 2050).all():\n",
    "                        return True # Only year\n",
    "            # For integer values\n",
    "            elif col_data.dropna().between(1800, 2100).all():\n",
    "                True # Only year\n",
    "                \n",
    "    return False\n",
    "\n",
    "def check_date_format(col_str):\n",
    "    # Check for common date formats (yyyy-mm-dd, dd-mm-yyyy, etc.)\n",
    "    date_pattern = r'^\\d{1,4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,4}$'\n",
    "    return col_str.str.match(date_pattern).all()\n",
    "\n",
    "def check_datetime_format(col_str):\n",
    "    # Check for datetime format (date + time)\n",
    "    datetime_pattern = r'\\d{1,4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,4}.*\\d{1,2}:\\d{2}'\n",
    "    return col_str.str.contains(datetime_pattern).all()\n",
    "\n",
    "def detectIdTypeCol(col_data):\n",
    "    if pd.api.types.is_string_dtype(col_data):\n",
    "        pattern = r'\\b[A-Z0-9]{1,4}[-_./]?[A-Z0-9]{2,6}[-_./]?[A-Z0-9]{0,5}\\b'\n",
    "        return all(re.fullmatch(pattern, item) for item in col_data)\n",
    "    \n",
    "def OneOr2digitDetection(col_data):\n",
    "    non2Digit=0\n",
    "    for v  in col_data:\n",
    "        if len(str(v)) >= 2:\n",
    "            non2Digit=o=non2Digit+1\n",
    "    \n",
    "    if len(col_data)/2.2 > non2Digit:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def detectSimpleDtypes(col_data):\n",
    "    if pd.api.types.is_integer_dtype(col_data):\n",
    "        return 'allInt'\n",
    "    if pd.api.types.is_float_dtype(col_data):\n",
    "        if col_data.isna().all()== False:\n",
    "            return 'numaric'\n",
    "    if pd.api.types.is_string_dtype(col_data) or pd.api.types.is_object_dtype(col_data):\n",
    "        return 'str'\n",
    "    return None\n",
    "\n",
    "def clusterDateTimeCol(fContent, col,no,ascending=True):\n",
    "    if no ==1:\n",
    "        # Try to detect and sort if the column is just year values\n",
    "        fContent = fContent.sort_values(by=col,ignore_index=True, ascending=ascending)\n",
    "        fContent = fContent.reset_index(drop=True)\n",
    "    elif no == 2 or 3:\n",
    "        # Now, try to detect proper date/datetime columns\n",
    "        try:\n",
    "            # Avoid processing numeric-only or zero-filled columns\n",
    "            sample_vals = fContent[col].astype(str).str.strip().replace('0', np.nan).dropna()\n",
    "            if len(sample_vals) == 0:\n",
    "                return fContent# All values are zero or empty-like\n",
    "            \n",
    "            # Try parsing\n",
    "            try:\n",
    "                parsed_col = pd.to_datetime(fContent[col], errors='raise')\n",
    "            except:\n",
    "                parsed_col = pd.to_datetime(fContent[col], dayfirst=True, errors='raise')\n",
    "               \n",
    "            if all(parsed_col.dt.time == pd.to_datetime('00:00:00').time()) and no == 2:  # Only date\n",
    "                fContent[col] = parsed_col\n",
    "                fContent = clean_and_sort_date_column(fContent, col, ascending)\n",
    "                fContent = fContent.reset_index(drop=True)\n",
    "                # Replace original column with parsed datetime values\n",
    "            elif no == 3:  # Date + time\n",
    "                fContent[col] = parsed_col\n",
    "                fContent = handle_datetime_column(fContent, col, ascending)\n",
    "                fContent = fContent.reset_index(drop=True)\n",
    "        except Exception as e:\n",
    "            return fContent # Not a datetime column\n",
    "        \n",
    "    return fContent \n",
    "\n",
    "def clean_and_sort_date_column(dff, column_name, ascending=True):\n",
    "        try:\n",
    "            \n",
    "            # Step 2: Drop NaT (invalid formats)\n",
    "            dff = dff.dropna(subset=[column_name])\n",
    "            \n",
    "            # Step 3: Sort the DataFrame by that column\n",
    "            dff = dff.sort_values(by=column_name, ascending=ascending)\n",
    "\n",
    "            # Optional: Format to clean date string (YYYY-MM-DD)\n",
    "            dff[column_name] = dff[column_name].dt.strftime('%Y-%m-%d')\n",
    "            print(f\"{column_name} date called \")\n",
    "            return dff\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error while processing date column: {e}\")\n",
    "            return dff\n",
    "\n",
    "def handle_datetime_column(df, column_name, ascending):\n",
    "    print(f\"{column_name} dateTime\")\n",
    "    # Check if most values in column are datetime with time\n",
    "    values = df[column_name].dropna().astype(str).head(20)\n",
    "    count_datetime = sum([pd.api.is_datetime(v) for v in values])\n",
    "\n",
    "    if count_datetime >= len(values) // 2:  # At least half must be datetime-like\n",
    "        # Convert full column to datetime\n",
    "        df[column_name] = pd.to_datetime(df[column_name], errors='coerce')\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=[column_name])\n",
    "        # Sort by that column\n",
    "        df = df.sort_values(by=column_name,ascending=ascending).reset_index(drop=True)\n",
    "        print(f\"[INFO] '{column_name}' successfully recognized and sorted as datetime.\")\n",
    "    else:\n",
    "        print(f\"[INFO] '{column_name}' does not contain proper datetime with time.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26207e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurCir(qc,q_num):\n",
    "    qc.measure(q_num,q_num)\n",
    "    simulator = AerSimulator()\n",
    "    # Transpile & run\n",
    "    compiled = transpile(qc, simulator)\n",
    "    r = simulator.run(compiled, shots=100000).result()\n",
    "    counts = r.get_counts()\n",
    "    for k,v in counts.items():\n",
    "        counts[k] = int(v/1000)\n",
    "    return counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
