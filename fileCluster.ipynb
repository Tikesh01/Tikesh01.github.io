{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901d784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check ieach column if NaN\n",
    "def checkColIfNaN(dff):\n",
    "    for i in dff.columns:\n",
    "        if dff[i].isna.empty:\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbb4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def detect_datetime_columns(df):\n",
    "    result = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_data = df[col]\n",
    "\n",
    "        # Handle if column is numeric and looks like a year\n",
    "        if pd.api.types.is_integer_dtype(col_data) or pd.api.types.is_float_dtype(col_data):\n",
    "            if col_data.dropna().empty == False:\n",
    "                if col_data.dropna().between(1800, 2100).all():\n",
    "                    result[col] = 1  # Only year\n",
    "                    continue\n",
    "\n",
    "        # Convert to string for flexible matching\n",
    "        col_str = df[col].astype(str).str.strip()\n",
    "\n",
    "        # Handle year-like strings\n",
    "        if col_str.str.match(r'^\\d{4}$').all():\n",
    "            print(\"date is str\")\n",
    "            if col_str.astype(int).between(1800, 2100).all():\n",
    "                result[col] = 1  # Only year\n",
    "                continue\n",
    "\n",
    "        # Check if values have full date (yyyy-mm-dd, dd-mm-yyyy, etc.)\n",
    "        if col_str.str.match(r'^\\d{1,4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,4}$').all():\n",
    "            result[col] = 2  # Only date\n",
    "            continue\n",
    "\n",
    "        # Check if values have date AND time\n",
    "        if col_str.str.contains(r'\\d{1,4}[-/\\.]\\d{1,2}[-/\\.]\\d{1,4}.*\\d{1,2}:\\d{2}').all():\n",
    "            result[col] = 3  # Date + Time\n",
    "            continue\n",
    "\n",
    "        # Else not a recognized datetime pattern\n",
    "        result[col] = 0\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7212af13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns = 12\n",
      "Total rows = 1000\n",
      "{'Index': 0, 'Customer Id': 0, 'First Name': 0, 'Last Name': 0, 'Company': 0, 'City': 0, 'Country': 0, 'Phone 1': 0, 'Phone 2': 0, 'Email': 0, 'Subscription Date': 2, 'Website': 0}\n",
      "Subscription Date date called \n",
      "last index called\n",
      "{2020: 425, 2021: 829, 2022: 999}\n",
      "[426, 404, 170]\n",
      "Multicalled\n",
      "Date Or DateTime\n",
      "                           Index      Customer Id First Name Last Name  \\\n",
      "Group              Sr No.                                                \n",
      "Group of year 2020 0          40  BEBA4fDAA6C4adC     Rickey      Mays   \n",
      "                   1         242  dEc837d5F13C1ed     Kendra    Waters   \n",
      "                   2         617  F9AEc2F51C5EDaE     Parker     Russo   \n",
      "                   3         148  EF5858dEe5f7649    Belinda  Ferguson   \n",
      "                   4         952  a9feB7dCD2FFd4e      Larry       Key   \n",
      "...                          ...              ...        ...       ...   \n",
      "Group of year 2022 995       772  cDBe5cFdbB3Ae4F     Jasmin    Waters   \n",
      "                   996       831  4A231C5DceB9739       Jack   Mendoza   \n",
      "                   997       498  E040edB499A6132     Amanda    Santos   \n",
      "                   998       198  a8FfE4fbd7910b9    Bethany   Barrera   \n",
      "                   999       578  aF4fA3aCA4bD5eC       Joel      Shea   \n",
      "\n",
      "                                               Company                 City  \\\n",
      "Group              Sr No.                                                     \n",
      "Group of year 2020 0       Escobar, Carrillo and Sloan         Hollandshire   \n",
      "                   1                         Gates Inc           Warnerport   \n",
      "                   2                       Foley-Yoder         East Dorothy   \n",
      "                   3           Lewis, Bowman and Craig          Moralesport   \n",
      "                   4                       Riley Group      Mcdonaldchester   \n",
      "...                                                ...                  ...   \n",
      "Group of year 2022 995                   Chandler-Holt  South Marisachester   \n",
      "                   996     Cardenas, Bass and Callahan            Quinnfurt   \n",
      "                   997                    Camacho-Lamb          Freemanberg   \n",
      "                   998     Swanson, Figueroa and Heath           Vickietown   \n",
      "                   999                  Richmond-Horne         South Alisha   \n",
      "\n",
      "                                                                Country  \\\n",
      "Group              Sr No.                                                 \n",
      "Group of year 2020 0                           United States of America   \n",
      "                   1                                          Nicaragua   \n",
      "                   2                                             Malawi   \n",
      "                   3                   Lao People's Democratic Republic   \n",
      "                   4                                             Guinea   \n",
      "...                                                                 ...   \n",
      "Group of year 2022 995                                          Hungary   \n",
      "                   996                                      Puerto Rico   \n",
      "                   997                              Antigua and Barbuda   \n",
      "                   998     South Georgia and the South Sandwich Islands   \n",
      "                   999                                            Palau   \n",
      "\n",
      "                                         Phone 1                Phone 2  \\\n",
      "Group              Sr No.                                                 \n",
      "Group of year 2020 0          042-976-4714x26341           245.657.5660   \n",
      "                   1                  5445638365           939.571.9576   \n",
      "                   2                800-134-7296      844-503-8567x9308   \n",
      "                   3                307.998.0543           007.052.7419   \n",
      "                   4        001-406-973-8446x255           811.758.6793   \n",
      "...                                          ...                    ...   \n",
      "Group of year 2022 995       (100)042-3614x67556             6319120275   \n",
      "                   996     +1-186-954-2345x50800  001-265-899-4876x1796   \n",
      "                   997         092.983.8391x0219     626-158-4763x92618   \n",
      "                   998          001-411-057-3486             6232251109   \n",
      "                   999     +1-517-016-8892x66533    (060)659-5698x44574   \n",
      "\n",
      "                                                  Email Subscription Date  \\\n",
      "Group              Sr No.                                                   \n",
      "Group of year 2020 0           cmcdowell@riley-wolf.org        2020-01-01   \n",
      "                   1                tracey11@carney.com        2020-01-02   \n",
      "                   2          hancockbrianna@mccann.org        2020-01-02   \n",
      "                   3              billspears@harmon.org        2020-01-02   \n",
      "                   4                   ygood@vaughn.com        2020-01-04   \n",
      "...                                                 ...               ...   \n",
      "Group of year 2022 995                pclark@ortega.com        2022-05-26   \n",
      "                   996           kmccullough@bryant.com        2022-05-28   \n",
      "                   997     slivingston@cherry-lara.info        2022-05-29   \n",
      "                   998             rhonda48@castro.info        2022-05-29   \n",
      "                   999        gfarley@wheeler-ayala.com        2022-05-29   \n",
      "\n",
      "                                                   Website  \n",
      "Group              Sr No.                                   \n",
      "Group of year 2020 0                 http://www.nolan.com/  \n",
      "                   1                 http://www.ayala.com/  \n",
      "                   2            https://perez-pollard.com/  \n",
      "                   3                     https://huff.com/  \n",
      "                   4       https://www.arroyo-schultz.com/  \n",
      "...                                                    ...  \n",
      "Group of year 2022 995            https://costa-owens.com/  \n",
      "                   996                  https://colon.net/  \n",
      "                   997        http://www.mcneil-gould.biz/  \n",
      "                   998              http://www.cortez.com/  \n",
      "                   999             https://www.mercer.com/  \n",
      "\n",
      "[1000 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_2816\\330670565.py:17: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise')\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_2816\\4054971873.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  last_indices = df.groupby('year').apply(lambda x: x.index[-1]).to_dict()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "mainDf = pd.read_csv('customers-1000.csv')#df is the data frame containing the whole content of file\n",
    "columns = np.array(mainDf.columns)#to know the number of colums in dataframe(csv) file\n",
    "noOfColumns = len(columns)\n",
    "noOfRows = len(mainDf.index)\n",
    "print(f\"Total columns = {noOfColumns}\")\n",
    "print(f\"Total rows = {noOfRows}\")\n",
    "sortAccordingToDateTime = detect_datetime_columns(mainDf)\n",
    "print(sortAccordingToDateTime)\n",
    "for col in mainDf.columns:\n",
    "    if sortAccordingToDateTime[col] in [1,2,3]:\n",
    "        mainDf = clusterDateTimeCol(mainDf,col,sortAccordingToDateTime[col]) \n",
    "        arrOfGroupNames = mainDf.index.get_level_values(0).unique()# this variable i containing the group names\n",
    "    else:\n",
    "        continue\n",
    "print(mainDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterDateTimeCol(fContent, col,no):\n",
    "    if no ==1:\n",
    "        # Try to detect and sort if the column is just year values\n",
    "        fContent = fContent.sort_values(by=col,ignore_index=True, ascending=True)\n",
    "        fContent = fContent.reset_index(drop=True)\n",
    "        fContent = multiIndex(fContent,col, True)\n",
    "    elif no == 2 or 3:\n",
    "        # Now, try to detect proper date/datetime columns\n",
    "        try:\n",
    "            # Avoid processing numeric-only or zero-filled columns\n",
    "          \n",
    "            sample_vals = fContent[col].astype(str).str.strip().replace('0', np.nan).dropna()\n",
    "            if len(sample_vals) == 0:\n",
    "                return fContent# All values are zero or empty-like\n",
    "            # Try parsing\n",
    "            try:\n",
    "                parsed_col = pd.to_datetime(fContent[col], errors='raise')\n",
    "            except:\n",
    "                parsed_col = pd.to_datetime(fContent[col], dayfirst=True, errors='raise')\n",
    "            if all(parsed_col.dt.time == pd.to_datetime('00:00:00').time()) and no == 2:  # Only date\n",
    "                fContent[col] = parsed_col\n",
    "                fContent = clean_and_sort_date_column(fContent, col, True)\n",
    "                fContent = fContent.reset_index(drop=True)\n",
    "                fContent = multiIndex(fContent,col)\n",
    "                # Replace original column with parsed datetime values\n",
    "            elif no == 3:  # Date + time\n",
    "                fContent[col] = parsed_col\n",
    "                fContent = handle_datetime_column(fContent, col, False)\n",
    "                fContent = fContent.reset_index(drop=True)\n",
    "                fContent = multiIndex(fContent,col)\n",
    "            print(\"Date Or DateTime\")\n",
    "        except Exception as e:\n",
    "            print(\"date year  datetime col flop\")\n",
    "            return fContent # Not a datetime column\n",
    "        \n",
    "   \n",
    "    return fContent \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca7e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuction which will sort the dates if the df has date containing columns\n",
    "def clean_and_sort_date_column(dff, column_name, ascending=True):\n",
    "        try:\n",
    "            # Step 1: Convert to datetime (handles multiple formats)\n",
    "            dff[column_name] = pd.to_datetime(dff[column_name], errors='coerce', dayfirst=True)\n",
    "            \n",
    "            # Step 2: Drop NaT (invalid formats)\n",
    "            dff = dff.dropna(subset=[column_name])\n",
    "            \n",
    "            # Step 3: Sort the DataFrame by that column\n",
    "            dff = dff.sort_values(by=column_name, ascending=ascending)\n",
    "\n",
    "            # Optional: Format to clean date string (YYYY-MM-DD)\n",
    "            dff[column_name] = dff[column_name].dt.strftime('%Y-%m-%d')\n",
    "            print(f\"{column_name} date called \")\n",
    "            return dff\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error while processing date column: {e}\")\n",
    "            return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c830a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df has column containing the date and time both\n",
    "def handle_datetime_column(df, column_name, ascending):\n",
    "    print(f\"{column_name} dateTime\")\n",
    "    # Check if most values in column are datetime with time\n",
    "    values = df[column_name].dropna().astype(str).head(20)\n",
    "    count_datetime = sum([is_datetime(v) for v in values])\n",
    "\n",
    "    if count_datetime >= len(values) // 2:  # At least half must be datetime-like\n",
    "        # Convert full column to datetime\n",
    "        df[column_name] = pd.to_datetime(df[column_name], errors='coerce')\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=[column_name])\n",
    "        # Sort by that column\n",
    "        df = df.sort_values(by=column_name,ascending=ascending).reset_index(drop=True)\n",
    "        print(f\"[INFO] '{column_name}' successfully recognized and sorted as datetime.\")\n",
    "    else:\n",
    "        print(f\"[INFO] '{column_name}' does not contain proper datetime with time.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142d61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fuction to get the years from teh date format\n",
    "def extract_year(date_str):\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', date_str)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return None\n",
    "\n",
    "# Function to extract all unique years from a pandas Series\n",
    "def extract_all_years(series):\n",
    "    print(\"extract_all_years called\")\n",
    "    setofyears = [None] * len(series)\n",
    "\n",
    "    for i in range(len(series)):\n",
    "        setofyears[i] = extract_year(str(series[i]).strip())\n",
    "\n",
    "    # Filter None values and return sorted unique years\n",
    "    return np.array(sorted(set(y for y in setofyears if y is not None)))\n",
    "\n",
    "\n",
    "def get_last_indices_of_each_year(date_series, YearOnly=False):\n",
    "    \n",
    "    # data_series = data_series.apply(pd.to_numeric, errors='coerce').astype('Int64')\n",
    "    if YearOnly == True:\n",
    "        print(\"yearOnly work\")\n",
    "        df = pd.DataFrame({'year': date_series}, index=np.arange(len(date_series)))\n",
    "    \n",
    "    else:\n",
    "        # Extract year\n",
    "        years = date_series.dt.year\n",
    "        \n",
    "        # Create a DataFrame with index\n",
    "        df = pd.DataFrame({'year': years}, index=np.arange(len(date_series)))\n",
    "        \n",
    "    # Get last index of each year group\n",
    "    last_indices = df.groupby('year').apply(lambda x: x.index[-1]).to_dict()\n",
    "    print(\"last index called\")\n",
    "    return last_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a59f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group(MultiIndexing) accordind to the condition \n",
    "def multiIndex(dataFrame, colToCheck, yearOnly = False):\n",
    "    # Step 1: Get last indices of each year\n",
    "    if yearOnly == True:\n",
    "        yearsWithLastIndex = get_last_indices_of_each_year(dataFrame[colToCheck], True)\n",
    "    else:\n",
    "        yearsWithLastIndex = get_last_indices_of_each_year(pd.to_datetime(dataFrame[colToCheck]))\n",
    "    print(yearsWithLastIndex)\n",
    "    nameOfGroups = list(yearsWithLastIndex.keys())\n",
    "    last_indices = list(yearsWithLastIndex.values())\n",
    "\n",
    "    # Step 2: Compute counts from last indices\n",
    "    group_sizes = []\n",
    "    prev = -1\n",
    "    for idx in last_indices:\n",
    "        group_sizes.append(idx - prev)\n",
    "        prev = idx\n",
    "    print(group_sizes)\n",
    "    # Step 3: Create array per group\n",
    "    objOfGroups = {\n",
    "        f'key{i}': np.array([f'Group of year {year}'] * group_sizes[i])\n",
    "        for i, year in enumerate(nameOfGroups)\n",
    "    }\n",
    "    \n",
    "    # Step 4: Combine into one array\n",
    "    outside = np.concatenate(list(objOfGroups.values()))\n",
    "    \n",
    "    # Step 5: Create inside index\n",
    "    inside = np.arange(len(outside))\n",
    "    \n",
    "    multi_index = pd.MultiIndex.from_arrays([outside, inside], names=[\"Group\", \"Sr No.\"])\n",
    "    \n",
    "    dataFrame = dataFrame.reindex(range(len(multi_index)))\n",
    "    dataFrame.set_index(multi_index,inplace=True,)\n",
    "    print(\"Multicalled\")\n",
    "    return dataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4aab1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Now time to cluster the file(data)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Now time to cluster the file(data)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "@app.route(\"/clusteringStart\", methods=[\"POST\"])\n",
    "def dataClustering():#FileToCluster is DF which is created to print through html table\n",
    "    #Process of creating appropriate DF to apply KMeans\n",
    "    noOfClusters = int(request.form.get(\"noOfCluster\"))\n",
    "    fileToClusterNumaric = MainDF.select_dtypes(include=[\"float64\", \"int64\"])# to Change the string type columns to int or float because KMeans() needs int or float type colum to mesure distance\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = (scaler.fit_transform((fileToClusterNumaric)))\n",
    "    \n",
    "    # Process of applying kMeans\n",
    "    Kmeans = KMeans(n_clusters = noOfClusters, random_state=42)\n",
    "    Kmeans_lables = Kmeans.fit(scaled_data)\n",
    "    # hence means returns a array So need to change into Dataframe\n",
    "    clusteredDF = pd.DataFrame(Kmeans_lables)\n",
    "\n",
    "    return render_template(\"index.html\", clusteredData = clusteredDF.to_html(classes=\"UploadedclusteredData\", border=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34cf086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if Only year\n",
    "def sort_if_year_column(column):\n",
    "    print(f\"{column.name } year only call\")\n",
    "    try:\n",
    "        # Step 1: Convert to string and strip whitespace\n",
    "        cleaned = column.astype(str).str.strip()\n",
    "        \n",
    "        # Step 2: Check if all values match 4-digit pattern\n",
    "        if cleaned.str.fullmatch(r'\\d{4}').all():\n",
    "            # Step 3: Convert to int and check valid year range\n",
    "            years = cleaned.astype(int)\n",
    "            if years.between(1800, 2050).all():\n",
    "                print(\"✅ Year-only column detected. Sorted.\")\n",
    "                return years.sort_values(ignore_index=True)\n",
    "            else:\n",
    "               pass\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    return False # Return as-is if not valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "610fd0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "obj = {\n",
    "    'o':0,\n",
    "    'oo':0,\n",
    "    'ooo':2,\n",
    "    'oooo':1\n",
    "}\n",
    "arr  = obj.values()\n",
    "if 1 in  arr or 2 in arr or 3 in arr:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
