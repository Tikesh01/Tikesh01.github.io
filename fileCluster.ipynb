{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212af13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns = 12\n",
      "Total rows = 1000\n",
      "Index dateTime\n",
      "Subscription Date date\n",
      "Multicalled\n",
      "                           Index      Customer Id First Name Last Name  \\\n",
      "Group              Sr No.                                                \n",
      "Group of year 2020 0          40  BEBA4fDAA6C4adC     Rickey      Mays   \n",
      "                   1         242  dEc837d5F13C1ed     Kendra    Waters   \n",
      "                   2         617  F9AEc2F51C5EDaE     Parker     Russo   \n",
      "                   3         148  EF5858dEe5f7649    Belinda  Ferguson   \n",
      "                   4         952  a9feB7dCD2FFd4e      Larry       Key   \n",
      "...                          ...              ...        ...       ...   \n",
      "Group of year 2022 995       772  cDBe5cFdbB3Ae4F     Jasmin    Waters   \n",
      "                   996       831  4A231C5DceB9739       Jack   Mendoza   \n",
      "                   997       498  E040edB499A6132     Amanda    Santos   \n",
      "                   998       198  a8FfE4fbd7910b9    Bethany   Barrera   \n",
      "                   999       578  aF4fA3aCA4bD5eC       Joel      Shea   \n",
      "\n",
      "                                               Company                 City  \\\n",
      "Group              Sr No.                                                     \n",
      "Group of year 2020 0       Escobar, Carrillo and Sloan         Hollandshire   \n",
      "                   1                         Gates Inc           Warnerport   \n",
      "                   2                       Foley-Yoder         East Dorothy   \n",
      "                   3           Lewis, Bowman and Craig          Moralesport   \n",
      "                   4                       Riley Group      Mcdonaldchester   \n",
      "...                                                ...                  ...   \n",
      "Group of year 2022 995                   Chandler-Holt  South Marisachester   \n",
      "                   996     Cardenas, Bass and Callahan            Quinnfurt   \n",
      "                   997                    Camacho-Lamb          Freemanberg   \n",
      "                   998     Swanson, Figueroa and Heath           Vickietown   \n",
      "                   999                  Richmond-Horne         South Alisha   \n",
      "\n",
      "                                                                Country  \\\n",
      "Group              Sr No.                                                 \n",
      "Group of year 2020 0                           United States of America   \n",
      "                   1                                          Nicaragua   \n",
      "                   2                                             Malawi   \n",
      "                   3                   Lao People's Democratic Republic   \n",
      "                   4                                             Guinea   \n",
      "...                                                                 ...   \n",
      "Group of year 2022 995                                          Hungary   \n",
      "                   996                                      Puerto Rico   \n",
      "                   997                              Antigua and Barbuda   \n",
      "                   998     South Georgia and the South Sandwich Islands   \n",
      "                   999                                            Palau   \n",
      "\n",
      "                                         Phone 1                Phone 2  \\\n",
      "Group              Sr No.                                                 \n",
      "Group of year 2020 0          042-976-4714x26341           245.657.5660   \n",
      "                   1                  5445638365           939.571.9576   \n",
      "                   2                800-134-7296      844-503-8567x9308   \n",
      "                   3                307.998.0543           007.052.7419   \n",
      "                   4        001-406-973-8446x255           811.758.6793   \n",
      "...                                          ...                    ...   \n",
      "Group of year 2022 995       (100)042-3614x67556             6319120275   \n",
      "                   996     +1-186-954-2345x50800  001-265-899-4876x1796   \n",
      "                   997         092.983.8391x0219     626-158-4763x92618   \n",
      "                   998          001-411-057-3486             6232251109   \n",
      "                   999     +1-517-016-8892x66533    (060)659-5698x44574   \n",
      "\n",
      "                                                  Email Subscription Date  \\\n",
      "Group              Sr No.                                                   \n",
      "Group of year 2020 0           cmcdowell@riley-wolf.org        2020-01-01   \n",
      "                   1                tracey11@carney.com        2020-01-02   \n",
      "                   2          hancockbrianna@mccann.org        2020-01-02   \n",
      "                   3              billspears@harmon.org        2020-01-02   \n",
      "                   4                   ygood@vaughn.com        2020-01-04   \n",
      "...                                                 ...               ...   \n",
      "Group of year 2022 995                pclark@ortega.com        2022-05-26   \n",
      "                   996           kmccullough@bryant.com        2022-05-28   \n",
      "                   997     slivingston@cherry-lara.info        2022-05-29   \n",
      "                   998             rhonda48@castro.info        2022-05-29   \n",
      "                   999        gfarley@wheeler-ayala.com        2022-05-29   \n",
      "\n",
      "                                                   Website  \n",
      "Group              Sr No.                                   \n",
      "Group of year 2020 0                 http://www.nolan.com/  \n",
      "                   1                 http://www.ayala.com/  \n",
      "                   2            https://perez-pollard.com/  \n",
      "                   3                     https://huff.com/  \n",
      "                   4       https://www.arroyo-schultz.com/  \n",
      "...                                                    ...  \n",
      "Group of year 2022 995            https://costa-owens.com/  \n",
      "                   996                  https://colon.net/  \n",
      "                   997        http://www.mcneil-gould.biz/  \n",
      "                   998              http://www.cortez.com/  \n",
      "                   999             https://www.mercer.com/  \n",
      "\n",
      "[1000 rows x 12 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4034705326.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  last_indices = df.groupby('year').apply(lambda x: x.index[-1]).to_dict()\n",
      "C:\\Users\\tikes\\AppData\\Local\\Temp\\ipykernel_19208\\4233717916.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: '1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(mainDf)\n\u001b[32m     16\u001b[39m arrOfGroupNames = mainDf.index.get_level_values(\u001b[32m1\u001b[39m).unique()\u001b[38;5;66;03m# this variable i containing the group names\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmainDf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marrOfGroupNames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1431\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1381\u001b[39m, in \u001b[36m_LocIndexer._get_label\u001b[39m\u001b[34m(self, label, axis)\u001b[39m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4293\u001b[39m, in \u001b[36mNDFrame.xs\u001b[39m\u001b[34m(self, key, axis, level, drop_level)\u001b[39m\n\u001b[32m   4290\u001b[39m     index = \u001b[38;5;28mself\u001b[39m.index\n\u001b[32m   4292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, MultiIndex):\n\u001b[32m-> \u001b[39m\u001b[32m4293\u001b[39m     loc, new_index = \u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   4294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_level:\n\u001b[32m   4295\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m lib.is_integer(loc):\n\u001b[32m   4296\u001b[39m             \u001b[38;5;66;03m# Slice index must be an integer or None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3290\u001b[39m, in \u001b[36mMultiIndex._get_loc_level\u001b[39m\u001b[34m(self, key, level)\u001b[39m\n\u001b[32m   3288\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m indexer, maybe_mi_droplevels(indexer, ilevels)\n\u001b[32m   3289\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3290\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3292\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m   3293\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.levels[level]._supports_partial_string_indexing\n\u001b[32m   3294\u001b[39m     ):\n\u001b[32m   3295\u001b[39m         \u001b[38;5;66;03m# check to see if we did an exact lookup vs sliced\u001b[39;00m\n\u001b[32m   3296\u001b[39m         check = \u001b[38;5;28mself\u001b[39m.levels[level].get_loc(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3391\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3388\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3390\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3391\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3394\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3395\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3396\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2980\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2979\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tikes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: '1'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "mainDf = pd.read_csv('.//customers-1000.csv')#df is the data frame containing the whole content of file\n",
    "columns = np.array(mainDf.columns)#to know the number of colums in dataframe(csv) file\n",
    "noOfColumns = len(columns)\n",
    "noOfRows = len(mainDf.index)\n",
    "print(f\"Total columns = {noOfColumns}\")\n",
    "print(f\"Total rows = {noOfRows}\")\n",
    "sortAccordingToDateTime = True\n",
    "sortAccordingToComment = False\n",
    "if sortAccordingToDateTime == True:\n",
    "    mainDf = clusterDateTimeCol(mainDf) \n",
    "print(mainDf)\n",
    "arrOfGroupNames = mainDf.index.get_level_values(0).unique()# this variable i containing the group names\n",
    "# print(mainDf.loc[f'{arrOfGroupNames[1]}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4f6e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def clusterDateTimeCol(fContent):\n",
    "        for col in fContent.columns:\n",
    "            a = sort_if_year_column(fContent[col])\n",
    "            if a == False:\n",
    "                pass\n",
    "            else:\n",
    "                fContent[col] = a\n",
    "                fContent = fContent.reset_index(drop=True)\n",
    "                fContent = multiIndex(fContent,col)\n",
    "            try:\n",
    "                # Try to convert the column to datetime (auto format detection)\n",
    "                #it is flexible for all type of date time format\n",
    "                parsed_col = pd.to_datetime(fContent[col], errors='raise', dayfirst=True)\n",
    "                # Check if all time values are 00:00:00 → meaning only dates\n",
    "                if all(parsed_col.dt.time == pd.to_datetime('00:00:00').time()): #it is for date only \n",
    "                    print(f\"{col} date\")\n",
    "                    fContent = clean_and_sort_date_column(fContent,col)\n",
    "                    fContent = fContent.reset_index(drop=True)\n",
    "                    fContent = multiIndex(fContent,col,)\n",
    "                else:# it is for both date and time\n",
    "                    print(f\"{col} dateTime\")\n",
    "                    fContent = handle_datetime_column(df,col)\n",
    "                    fContent = fContent.reset_index(drop=True)\n",
    "                    fContent = multiIndex(fContent,col)\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return fContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff76d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if Only year\n",
    "def sort_if_year_column(column):\n",
    "    try:\n",
    "        # Step 1: Convert to string and strip whitespace\n",
    "        cleaned = column.astype(str).str.strip()\n",
    "        \n",
    "        # Step 2: Check if all values match 4-digit pattern\n",
    "        if cleaned.str.fullmatch(r'\\d{4}').all():\n",
    "            # Step 3: Convert to int and check valid year range\n",
    "            years = cleaned.astype(int)\n",
    "            if years.between(1800, 2050).all():\n",
    "                print(\"✅ Year-only column detected. Sorted.\")\n",
    "                return years.sort_values(ignore_index=True)\n",
    "            else:\n",
    "               pass\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    return False # Return as-is if not valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ca7e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuction which will sort the dates if the df has date containing columns\n",
    "def clean_and_sort_date_column(dff, column_name, ascending=True):\n",
    "    try:\n",
    "         # Step 1: Convert to datetime (handles multiple formats)\n",
    "        dff[column_name] = pd.to_datetime(dff[column_name], errors='coerce', dayfirst=True)\n",
    "        \n",
    "        # Step 2: Drop NaT (invalid formats)\n",
    "        dff = dff.dropna(subset=[column_name])\n",
    "        \n",
    "        # Step 3: Sort the DataFrame by that column\n",
    "        dff = dff.sort_values(by=column_name, ascending=ascending)\n",
    "\n",
    "        # Optional: Format to clean date string (YYYY-MM-DD)\n",
    "        dff[column_name] = dff[column_name].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        return dff\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error while processing date column: {e}\")\n",
    "        return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c830a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df has column containing the date and time both\n",
    "def handle_datetime_column(df, column_name, ascending):\n",
    "\n",
    "    # Check if most values in column are datetime with time\n",
    "    values = df[column_name].dropna().astype(str).head(20)\n",
    "    count_datetime = sum([is_datetime(v) for v in values])\n",
    "\n",
    "    if count_datetime >= len(values) // 2:  # At least half must be datetime-like\n",
    "        # Convert full column to datetime\n",
    "        df[column_name] = pd.to_datetime(df[column_name], errors='coerce')\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=[column_name])\n",
    "        # Sort by that column\n",
    "        df = df.sort_values(by=column_name,ascending=ascending).reset_index(drop=True)\n",
    "        print(f\"[INFO] '{column_name}' successfully recognized and sorted as datetime.\")\n",
    "    else:\n",
    "        print(f\"[INFO] '{column_name}' does not contain proper datetime with time.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "142d61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction to get the years from teh date format\n",
    "def extract_year(date_str):\n",
    "    match = re.search(r'\\b(19|20)\\d{2}\\b', date_str)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    return None\n",
    "\n",
    "# Function to extract all unique years from a pandas Series\n",
    "def extract_all_years(series):\n",
    "    print(\"extract_all_years called\")\n",
    "    setofyears = [None] * len(series)\n",
    "\n",
    "    for i in range(len(series)):\n",
    "        setofyears[i] = extract_year(str(series[i]).strip())\n",
    "\n",
    "    # Filter None values and return sorted unique years\n",
    "    return np.array(sorted(set(y for y in setofyears if y is not None)))\n",
    "\n",
    "\n",
    "def get_last_indices_of_each_year(date_series):\n",
    "    # Extract year\n",
    "    years = date_series.dt.year\n",
    "    \n",
    "    # Create a DataFrame with index\n",
    "    df = pd.DataFrame({'year': years})\n",
    "    \n",
    "    # Get last index of each year group\n",
    "    last_indices = df.groupby('year').apply(lambda x: x.index[-1]).to_dict()\n",
    "    \n",
    "    return last_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a59f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group(MultiIndexing) accordind to the condition \n",
    "def multiIndex(dataFrame, colToCheck):\n",
    "    print(\"Multicalled\")\n",
    "    \n",
    "    # Step 1: Get last indices of each year\n",
    "    yearsWithLastIndex = get_last_indices_of_each_year(pd.to_datetime(dataFrame[colToCheck]))\n",
    "    nameOfGroups = list(yearsWithLastIndex.keys())\n",
    "    last_indices = list(yearsWithLastIndex.values())\n",
    "    \n",
    "    # Step 2: Compute counts from last indices\n",
    "    group_sizes = []\n",
    "    prev = -1\n",
    "    for idx in last_indices:\n",
    "        group_sizes.append(idx - prev)\n",
    "        prev = idx\n",
    "    \n",
    "    # Step 3: Create array per group\n",
    "    objOfGroups = {\n",
    "        f'key{i}': np.array([f'Group of year {year}'] * group_sizes[i])\n",
    "        for i, year in enumerate(nameOfGroups)\n",
    "    }\n",
    "\n",
    "    # Step 4: Combine into one array\n",
    "    outside = np.concatenate(list(objOfGroups.values()))\n",
    "    \n",
    "    # Step 5: Create inside index\n",
    "    inside = np.arange(len(outside))\n",
    "    \n",
    "    multi_index = pd.MultiIndex.from_arrays([outside, inside], names=[\"Group\", \"Sr No.\"])\n",
    "    \n",
    "    dataFrame.set_index(multi_index,inplace=True)\n",
    "    return dataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4aab1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
